{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d8fe10",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2888b630",
   "metadata": {},
   "source": [
    "## Loading Libraries & Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import streamlit as st\n",
    "import missingno as msno\n",
    "import re\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import skew, boxcox, mstats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import TargetEncoder, OneHotEncoder, OrdinalEncoder, StandardScaler, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, Lasso, ElasticNetCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce549770",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = pd.read_csv(r\"laptop_prices.csv\")\n",
    "path_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e61e5d0",
   "metadata": {},
   "source": [
    "## A quick overview **(EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7197d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d8e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e5e5d",
   "metadata": {},
   "source": [
    "No missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42d54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.matrix(path_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728fd18",
   "metadata": {},
   "source": [
    "No duplicates in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d550d0",
   "metadata": {},
   "source": [
    "### ~`Company`\n",
    "Column seems to have a high cardinality between it's results due to companies having bigger market shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40287559",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_names = path_df[\"Company\"].unique()\n",
    "print(f\"Laptop companies: {company_names}\")\n",
    "\n",
    "plt.figure(figsize= (18,12))\n",
    "\n",
    "company_counts = path_df[\"Company\"].value_counts()\n",
    "avg_company_count = company_counts.mean()\n",
    "\n",
    "# List comprehension for color condition\n",
    "colors = [\"green\" if count >= avg_company_count else \"red\" for count in company_counts]\n",
    "\n",
    "sns.countplot(x = \"Company\",\n",
    "              data = path_df,\n",
    "              order = company_counts.index,\n",
    "              palette = colors,\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Market shares of laptop companies\")\n",
    "# Average count line\n",
    "plt.axhline(y = avg_company_count,\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label = f\"Mean: {avg_company_count:.0f}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6416bd03",
   "metadata": {},
   "source": [
    "### `Product`\n",
    "Column has repeated entries (nothing concerning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5bb282",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df[\"Product\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfaab63",
   "metadata": {},
   "source": [
    "### ~`TypeName`\n",
    "**Notebooks** seem to be the most popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98e53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_types = path_df[\"TypeName\"].nunique()\n",
    "print(f\"Laptop types: {unique_types}\")\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "\n",
    "typecounts = path_df[\"TypeName\"].value_counts()\n",
    "\n",
    "sns.countplot(x = \"TypeName\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\",\n",
    "              order = typecounts.index)\n",
    "plt.title(\"Laptop type popularity\")\n",
    "plt.xlabel(\"Laptop Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67aa9f3",
   "metadata": {},
   "source": [
    "### `Inches`\n",
    "Column seemed to have multiple high leverage points that after a deep research it was concluded that they weren't outliers. They were small sized due to them mostly being convertibles or small netbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_size = path_df[\"Inches\"].mean()\n",
    "print(f\"Average laptop size: {avg_size:.0f} inches\")\n",
    "\n",
    "Q1 = path_df[\"Inches\"].quantile(0.25)\n",
    "Q3 = path_df[\"Inches\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = path_df[(path_df[\"Inches\"] < lower) | (path_df[\"Inches\"] > upper)]\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "print(f\"Outlier bounds: [{lower:.2f}, {upper:.2f}]\")\n",
    "display(outliers)\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "sns.boxplot(x = \"Inches\",\n",
    "            data = path_df,\n",
    "            color = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b8b56",
   "metadata": {},
   "source": [
    "### `Ram`\n",
    "Just like last column. `Ram` Also had high leverage points in terms of ram capacity beihng above the average in some cases. That was due to these laptops being a high performance **gaming** or **workstation** laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f9a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ram = path_df[\"Ram\"].mean()\n",
    "print(f\"Average laptop ram: {avg_ram:.0f} GB\")\n",
    "\n",
    "Q1 = path_df[\"Ram\"].quantile(0.25)\n",
    "Q3 = path_df[\"Ram\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = path_df[(path_df[\"Ram\"] < lower) | (path_df[\"Ram\"] > upper)]\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "print(f\"Outlier bounds: [{lower:.2f}, {upper:.2f}]\")\n",
    "display(outliers)\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "sns.boxplot(x = \"Ram\",\n",
    "            data = path_df,\n",
    "            color = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef8ca7",
   "metadata": {},
   "source": [
    "### ~`OS`\n",
    "We see high cardinality of categorical variables with a large dominance of windows 10 being the main OS for most laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a71d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_counts = path_df[\"OS\"].value_counts()\n",
    "os_avg = os_counts.mean()\n",
    "os_num = path_df[\"OS\"].nunique()\n",
    "print(f\"There are a total of {os_num} operating systems in the market\")\n",
    "\n",
    "color = [\"green\" if count > os_avg else \"red\" for count in os_counts]\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "sns.countplot(x = \"OS\",\n",
    "              data = path_df,\n",
    "              palette = color,\n",
    "              order = os_counts.index,\n",
    "              edgecolor = \"black\")\n",
    "plt.axhline(y = os_avg,\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label = f\"Mean: {os_avg:.0f}\")\n",
    "plt.legend()\n",
    "plt.title(\"Preinstalled operating systems in laptops\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075faf3c",
   "metadata": {},
   "source": [
    "### `Weight`\n",
    "There seems to be a couple influencial entires where they weigh more than 2.71 KG but it's to be expected due to their bigger surface area compared to other laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21e4597",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_weight = path_df[\"Weight\"].mean()\n",
    "print(f\"Average weight: {avg_weight:.2f} KG\")\n",
    "\n",
    "Q1 = path_df[\"Weight\"].quantile(0.25)\n",
    "Q3 = path_df[\"Weight\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q1 + 1.5 * IQR\n",
    "\n",
    "outliers = path_df[(path_df[\"Weight\"] < lower) | (path_df[\"Weight\"] > upper)]\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "print(f\"Outlier bounds: [{lower:.2f}, {upper:.2f}]\")\n",
    "display(outliers)\n",
    "\n",
    "plt.figure(figsize = (18,12))\n",
    "sns.boxplot(x = \"Weight\",\n",
    "            data = path_df,\n",
    "            color = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7709ca",
   "metadata": {},
   "source": [
    "As we see, there's a positive linear relationship between the laptop size in inches and its weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4beaaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.regplot(x = \"Inches\",\n",
    "                y = \"Weight\",\n",
    "                data = path_df,\n",
    "                scatter_kws = {\"color\" : \"grey\", \"alpha\" : 0.8},\n",
    "                line_kws = {\"color\" : \"red\", \"linewidth\" : 2})\n",
    "plt.title(\"Relationship between laptop size & weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9f8ab1",
   "metadata": {},
   "source": [
    "### `Price_euros`\n",
    "Price seems to be skewed which will need transformation to adjust and normalize or checking outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201b6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_skew(x):\n",
    "    if abs(x) > 1:\n",
    "        return \"Very skewed\"\n",
    "    elif 0.5 <= abs(x) <= 1:\n",
    "        return \"Moderately skewed\"\n",
    "    else : \n",
    "        return \"Symmetrical\"\n",
    "def state_kurtosis(x):\n",
    "    if x > 1:\n",
    "        return \"Leptokurtic (Many Outliers)\"\n",
    "    elif x < -1:\n",
    "        return \"Playtukurtic (Few Outliers)\"\n",
    "    else :\n",
    "        return \"Mesokurtic (Normal tails)\"\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (12, 10))\n",
    "sns.histplot(x = \"Price_euros\",\n",
    "             data = path_df,\n",
    "             color = \"grey\",\n",
    "             edgecolor = \"black\",\n",
    "             kde = True,\n",
    "             ax = ax1)\n",
    "ax1.set_title(\"Checking column normality\")\n",
    "sns.regplot(x = \"Price_euros\",\n",
    "                y = \"Weight\",\n",
    "                data = path_df,\n",
    "                scatter_kws = {\"color\" : \"grey\", \"alpha\" : 0.8},\n",
    "                line_kws = {\"color\" : \"red\", \"linewidth\" : 2},\n",
    "                ax = ax2)\n",
    "ax2.set_title(\"Relationship of price with weight\")\n",
    "plt.show()\n",
    "\n",
    "price_kurtosis = path_df[\"Price_euros\"].kurtosis()\n",
    "price_skew = path_df[\"Price_euros\"].skew()\n",
    "print(f\"Price kurtosis before transformation: {price_kurtosis:.2f}, {state_kurtosis(price_kurtosis)}\")\n",
    "print(f\"Price skew before transformation: {price_skew:.2f}, {state_skew(price_skew)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a02a47",
   "metadata": {},
   "source": [
    "From what we can see is there are multiple outliers that could affect the modeling phase.\n",
    "After further investigation they could seem dangerous but after transformation most likely it'll be completely normalized due to these highly priced laptops being either workstation, ultrabooks or gaming laptops that have alot of expensive parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_price = path_df[\"Price_euros\"].mean()\n",
    "print(f\"Average price: {avg_price:.2f}€\")\n",
    "\n",
    "Q1 = path_df[\"Price_euros\"].quantile(0.25)\n",
    "Q3 = path_df[\"Price_euros\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower = Q1 - 1.5 * IQR\n",
    "upper = Q1 + 1.5 * IQR\n",
    "\n",
    "outliers = path_df[(path_df[\"Price_euros\"] < lower) | (path_df[\"Price_euros\"] > upper)]\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "print(f\"Outlier bounds: [{lower:.2f}, {upper:.2f}]\")\n",
    "display(outliers)\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.boxplot(x = \"Price_euros\",\n",
    "            data = path_df,\n",
    "            color = \"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45995d",
   "metadata": {},
   "source": [
    "### ~`Screen`, `ScreenW`, & `ScreemH`\n",
    "Dominance of **Full HD** & **Standard** over the laptop market (High Cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be67a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_count = path_df[\"Screen\"].value_counts()\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.pie(screen_count.values,\n",
    "        colors = sns.color_palette(\"Set2\"),\n",
    "        autopct = \"%1.1f%%\",\n",
    "        explode = [0, 0.1, 0, 0])  # Shows percentage\n",
    "plt.title(\"Laptop screens by popularity\")\n",
    "plt.legend(labels = screen_count.index,\n",
    "           title = \"Screen type\",\n",
    "           loc = \"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc741915",
   "metadata": {},
   "source": [
    "**1920x1080p** dominated laptop screens and to this day it's the most popular and most used resolution although **2560x1440p** & **3840x2160p** (also known as **4K**) has been getting more popular in the recent years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765611f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the full screen resolution\n",
    "path_df[\"Resolution\"] = path_df[\"ScreenW\"].astype(str) + \"x\" + path_df[\"ScreenH\"].astype(str)\n",
    "res_count = path_df[\"Resolution\"].value_counts()\n",
    "avg_res = res_count.mean()\n",
    "\n",
    "color = [\"green\" if count >= avg_res else \"red\" for count in res_count]\n",
    "\n",
    "plt.figure(figsize = (18, 12))\n",
    "sns.countplot(x = \"Resolution\",\n",
    "              data = path_df,\n",
    "              order = res_count.index,\n",
    "              palette = color,\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Most popular laptop resolutions\")\n",
    "plt.axhline(y = avg_res,\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label = f\"Mean: {avg_res:.0f}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291f9f69",
   "metadata": {},
   "source": [
    "### ~`Touchscreen`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96d0476",
   "metadata": {},
   "outputs": [],
   "source": [
    "touch_count = path_df[\"Touchscreen\"].value_counts()\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.pie(touch_count.values,\n",
    "        colors = sns.color_palette(\"Set2\"),\n",
    "        autopct = \"%1.1f%%\",\n",
    "        explode = [0, 0.1])\n",
    "plt.title(\"Touchscreen laptop proportion\")\n",
    "plt.legend(labels = touch_count.index,\n",
    "           title = \"Touchscreen ?\",\n",
    "           loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332462c3",
   "metadata": {},
   "source": [
    "### ~`IPSpanel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ips_count = path_df[\"IPSpanel\"].value_counts()\n",
    "\n",
    "plt.figure(figsize = (10, 8))\n",
    "plt.pie(ips_count.values,\n",
    "        colors = sns.color_palette(\"Set2\"),\n",
    "        autopct = \"%1.1f%%\",\n",
    "        explode = [0, 0.1])\n",
    "plt.title(\"IPS screens laptop proportion\")\n",
    "plt.legend(labels = ips_count.index,\n",
    "           title = \"IPS ?\",\n",
    "           loc = \"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13ef25",
   "metadata": {},
   "source": [
    "### ~`RetinaDisplay`\n",
    "Very little laptops had retina display screens where this technology was mostly unique to apple macbooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c62022",
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_count = path_df[\"RetinaDisplay\"].value_counts()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (10,8))\n",
    "ax2.pie(retina_count.values,\n",
    "        colors = sns.color_palette(\"Set2\"),\n",
    "        autopct = \"%1.1f%%\")\n",
    "ax2.legend(labels = retina_count.index,\n",
    "           title = \"Retina ?\",\n",
    "           loc = \"upper right\")\n",
    "ax2.set_title(\"Retina display laptop proportion\")\n",
    "\n",
    "# Showing only companies making retina display laptops\n",
    "retina_by_company = path_df[path_df[\"RetinaDisplay\"] == \"Yes\"].groupby(\"Company\")[\"RetinaDisplay\"].count().sort_values(ascending = False)\n",
    "retina_companies = retina_by_company[retina_by_company > 0]\n",
    "\n",
    "sns.barplot(x = retina_companies.index,\n",
    "            y = retina_companies.values,\n",
    "            color = \"grey\",\n",
    "            edgecolor = \"black\",\n",
    "            ax = ax1)\n",
    "ax1.set_title(\"Retina display by company\")\n",
    "ax1.tick_params(axis = \"x\", rotation = 45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Only {retina_companies.shape[0]} companies have retina display laptops\")\n",
    "print(f\"Total Retina laptops: {retina_count.get(1, 0)} ({retina_count.get(1, 0)/len(path_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487239c",
   "metadata": {},
   "source": [
    "### ~`CPU_company`\n",
    "Intel holds a massive market share in CPUs for laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 10))\n",
    "sns.countplot(x = \"CPU_company\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Laptop cpu companies market shares\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d29893",
   "metadata": {},
   "source": [
    "### `CPU_freq`\n",
    "Although **Intel** holds the bigger marketshare. **AMD** seems to have the better performing CPUs on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1547e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_company_freq = path_df.groupby(\"CPU_company\")[\"CPU_freq\"].mean().sort_values(ascending = False).round(1)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (12, 10))\n",
    "sns.histplot(x = \"CPU_freq\",\n",
    "             data = path_df,\n",
    "             color = \"grey\",\n",
    "             edgecolor = \"black\",\n",
    "             kde = True,\n",
    "             ax = ax1)\n",
    "ax1.set_title(\"Laptop CPU clock speed distribution\")\n",
    "ax1.set_ylabel(\"Frequency (GHz)\")\n",
    "\n",
    "sns.barplot(x = cpu_company_freq.index,\n",
    "            y = cpu_company_freq.values,\n",
    "            palette = \"Set2\",\n",
    "            edgecolor = \"black\",\n",
    "            ax = ax2)\n",
    "ax2.set_title(\"Average CPU clock speed per company\")\n",
    "ax2.set_ylabel(\"Frequency (GHz)\")\n",
    "for i, v in enumerate(cpu_company_freq.values):\n",
    "    ax2.text(i, v - 0.15, f\"{v:.1f}GHz\", ha = \"center\", fontweight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac214af",
   "metadata": {},
   "source": [
    "### ~`CPU_model`\n",
    "There is a massive popularity of \"**Core i**\" models compared to other models of **Intel** and other CPU companies (High Cardinality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23550713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting \n",
    "def extract_cpu_model(cpu_string):\n",
    "    patterns = [\n",
    "        r'(Core [im]\\d)',           # Core i3, i5, i7, i9, m3, m5, etc...\n",
    "        r'(Ryzen \\d)',              # Ryzen 3, 5, 7\n",
    "        r'(Atom [xX]\\d)',           # Atom x5, x7\n",
    "        r'(Celeron)',               # Celeron\n",
    "        r'(Pentium)',               # Pentium\n",
    "        r'(Xeon)',                  # Xeon\n",
    "        r'(A\\d+)',                  # AMD A6, A9, A10, A12, etc...\n",
    "        r'(E2)',                    # AMD E2\n",
    "        r'(FX)',                    # AMD FX\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, cpu_string, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    return \"Other\"\n",
    "\n",
    "path_df[\"CPU_series\"] = path_df[\"CPU_model\"].apply(extract_cpu_model)\n",
    "series_counts = path_df[\"CPU_series\"].value_counts()\n",
    "avg_series = series_counts.mean()\n",
    "\n",
    "colors = [\"green\" if count > avg_series else \"red\" for count in series_counts]\n",
    "\n",
    "plt.figure(figsize = (16,10))\n",
    "sns.countplot(x = \"CPU_series\",\n",
    "              data = path_df,\n",
    "              palette = colors,\n",
    "              order = series_counts.index,\n",
    "              edgecolor = \"black\")\n",
    "plt.axhline(y = avg_series,\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label =f\"Mean: {avg_series:.0f}\")\n",
    "plt.legend()\n",
    "plt.title(\"CPU models popularity in laptops\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf3d36",
   "metadata": {},
   "source": [
    "### `PrimaryStorage`\n",
    "Most laptops had **256GBs** as a primary drive that had their operating system on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9dd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.countplot(x = \"PrimaryStorage\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Primary storage popularity in GBs\")\n",
    "plt.xlabel(\"GBs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042a3a82",
   "metadata": {},
   "source": [
    "### `SecondaryStorage`\n",
    "Most laptops don't have any secondary hard drives installed which could result in an imbalance in modeling later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e1f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.countplot(x = \"SecondaryStorage\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Secondary storage popularity in GBs\")\n",
    "plt.xlabel(\"GBs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba22a77",
   "metadata": {},
   "source": [
    "### ~`PrimaryStorageType`\n",
    "**SSDs** generally have been the most popular storage type due to their fast read and write frequency & longevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e356e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.countplot(x = \"PrimaryStorageType\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Primary storage type popularity\")\n",
    "plt.xlabel(\"Storage Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4071fd",
   "metadata": {},
   "source": [
    "### ~`SecondaryStorageType`\n",
    "Surprisingly laptops that do have a seconadry storage installed usually use **HDD** which means that usually use secondary storage to store important files and don't need to use the massive read & write speeds that an **SSD** provides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ea77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.countplot(x = \"SecondaryStorageType\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Secondary storage type popularity\")\n",
    "plt.xlabel(\"Storage Type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e940605",
   "metadata": {},
   "source": [
    "### ~`GPU_company`\n",
    "**Intel** has the largest market share which is expected due to them winning by a landslide in CPUs as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960cbbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,10))\n",
    "sns.countplot(x = \"GPU_company\",\n",
    "              data = path_df,\n",
    "              palette = \"Set2\",\n",
    "              edgecolor = \"black\")\n",
    "plt.title(\"Laptop GPU companies market share\")\n",
    "plt.xlabel(\"GPU Companies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3194086f",
   "metadata": {},
   "source": [
    "### ~`GPU_model`\n",
    "**Intel integrated graphics** had the highest market share due to them being present in most budget to medium priced laptop without a dedicated GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting GPU series\n",
    "def extract_gpu_model(gpu_string):\n",
    "    gpu_string = str(gpu_string)\n",
    "    \n",
    "    # NVIDIA patterns\n",
    "    if re.search(r'GTX', gpu_string, re.IGNORECASE):                    # GTX\n",
    "        return \"GeForce GTX\"\n",
    "    elif re.search(r'MX\\d{3}', gpu_string, re.IGNORECASE):              # MX\n",
    "        return \"GeForce MX\"\n",
    "    elif re.search(r'GeForce \\d{3}', gpu_string, re.IGNORECASE):        # GeForce\n",
    "        return \"GeForce (Low-end)\"\n",
    "    elif re.search(r'Quadro', gpu_string, re.IGNORECASE):               # Quadro\n",
    "        return \"Quadro\"\n",
    "    \n",
    "    # AMD patterns\n",
    "    elif re.search(r'Radeon Pro', gpu_string, re.IGNORECASE):           # Radeon Pro\n",
    "        return \"Radeon Pro\"\n",
    "    elif re.search(r'Radeon RX', gpu_string, re.IGNORECASE):            # Radeon RX\n",
    "        return \"Radeon RX\"\n",
    "    elif re.search(r'Radeon R\\d', gpu_string, re.IGNORECASE):           # Radeon R\n",
    "        return \"Radeon R\"\n",
    "    elif re.search(r'Radeon', gpu_string, re.IGNORECASE):               # Radeon 530, etc...\n",
    "        return \"Radeon (Other)\"\n",
    "    \n",
    "    # Intel patterns\n",
    "    elif re.search(r'UHD Graphics', gpu_string, re.IGNORECASE):         # UHD Graphics 550, etc...\n",
    "        return \"Intel UHD\"\n",
    "    elif re.search(r'Iris Plus', gpu_string, re.IGNORECASE):            # Iris\n",
    "        return \"Intel Iris Plus\"\n",
    "    elif re.search(r'Iris Pro', gpu_string, re.IGNORECASE):             # Iris Pro\n",
    "        return \"Intel Iris Pro\"\n",
    "    elif re.search(r'Iris', gpu_string, re.IGNORECASE):                 # Iris\n",
    "        return \"Intel Iris\"\n",
    "    elif re.search(r'HD Graphics', gpu_string, re.IGNORECASE):          # HD Graphics\n",
    "        return \"Intel HD\"\n",
    "    \n",
    "    return \"Other\"\n",
    "\n",
    "path_df[\"GPU_series\"] = path_df[\"GPU_model\"].apply(extract_gpu_model)\n",
    "gpu_series_counts = path_df[\"GPU_series\"].value_counts()\n",
    "avg_gpu_series = gpu_series_counts.mean()\n",
    "\n",
    "colors = [\"green\" if count > avg_gpu_series else \"red\" for count in gpu_series_counts]\n",
    "\n",
    "plt.figure(figsize = (12, 10))\n",
    "sns.countplot(x = \"GPU_series\",\n",
    "              data = path_df,\n",
    "              palette = colors,\n",
    "              order = gpu_series_counts.index,\n",
    "              edgecolor = \"black\")\n",
    "plt.axhline(y = avg_gpu_series,\n",
    "            color = \"black\",\n",
    "            linestyle = \"--\",\n",
    "            label = f\"Mean: {avg_gpu_series:.0f}\")\n",
    "plt.legend()\n",
    "plt.title(\"GPU series popularity in laptops\")\n",
    "plt.xlabel(\"GPU Series\")\n",
    "plt.xticks(rotation = 45, ha = \"right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0251c303",
   "metadata": {},
   "source": [
    "## Choosing the variables (Feature Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a2166b",
   "metadata": {},
   "source": [
    "### `Price_euros` **Log Transformation**\n",
    "Using the log transformation has successfully normalized the column which made it suitable for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b30af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df[\"Price_transformed\"] = path_df[\"Price_euros\"].apply(np.log).round(2)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (12, 10))\n",
    "sns.histplot(x = \"Price_transformed\",\n",
    "             data = path_df,\n",
    "             color = \"grey\",\n",
    "             edgecolor = \"black\",\n",
    "             kde = True,\n",
    "             ax = ax1)\n",
    "ax1.set_title(\"Checking column normality\")\n",
    "sns.regplot(x = \"Price_transformed\",\n",
    "                y = \"Weight\",\n",
    "                data = path_df,\n",
    "                scatter_kws = {\"color\" : \"grey\", \"alpha\" : 0.8},\n",
    "                line_kws = {\"color\" : \"red\", \"linewidth\" : 2},\n",
    "                ax = ax2)\n",
    "ax2.set_title(\"Relationship of price with weight\")\n",
    "plt.show()\n",
    "\n",
    "price_kurtosis = path_df[\"Price_transformed\"].kurtosis()\n",
    "price_skew = path_df[\"Price_transformed\"].skew()\n",
    "print(f\"Price kurtosis before transformation: {price_kurtosis:.2f}, {state_kurtosis(price_kurtosis)}\")\n",
    "print(f\"Price skew before transformation: {price_skew:.2f}, {state_skew(price_skew)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6954efdb",
   "metadata": {},
   "source": [
    "### `Company`, `CPU_series` `GPU_series` **TE with smoothing**\n",
    "Due to their high cardinality and imbalance we will use target encoding to reduce overfitting and smoothing to reduce data leakage.\n",
    "Reducing cardinality by reducing the number of insignificant variables in these 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fa1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "others = {\"Company\": company_counts,\n",
    "          \"CPU_series\": series_counts,\n",
    "          \"GPU_series\": gpu_series_counts}\n",
    "\n",
    "others_avg = {\"Company\": avg_company_count,\n",
    "          \"CPU_series\": avg_series,\n",
    "          \"GPU_series\": avg_gpu_series}\n",
    "\n",
    "# Function that returns variable names that are less than the average EXCLUDING Apple due to having a neiche share of the market\n",
    "def to_other(vals, avg):\n",
    "    hitlist = vals.values < avg\n",
    "    red = vals.index[hitlist]\n",
    "    red = [name for name in red if name != \"Apple\"]\n",
    "    return red\n",
    "    \n",
    "for col, v in others.items():\n",
    "    other_vars = to_other(v, others_avg[col])\n",
    "    path_df[col] = path_df[col].replace(other_vars, \"Other\")\n",
    "    \n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (18,8))\n",
    "sns.countplot(x = \"Company\",\n",
    "             data = path_df,\n",
    "             palette = \"Set2\",\n",
    "             edgecolor = \"black\",\n",
    "             ax = ax1)\n",
    "ax1.set_title(\"Company column after reducing cardinality\")\n",
    "\n",
    "sns.countplot(x = \"CPU_series\",\n",
    "             data = path_df,\n",
    "             palette = \"Set2\",\n",
    "             edgecolor = \"black\",\n",
    "             ax = ax2)\n",
    "ax2.set_title(\"CPU_series column after reducing cardinality\")\n",
    "\n",
    "plt.figure(figsize = (18,8))\n",
    "sns.countplot(x = \"GPU_series\",\n",
    "             data = path_df,\n",
    "             palette = \"Set2\",\n",
    "             edgecolor = \"black\")\n",
    "plt.title(\"GPU_series column after reducing cardinality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bd493",
   "metadata": {},
   "source": [
    "Target encoding using kfold on 5 folds to reduce data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4c2482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Folds\n",
    "encoder = TargetEncoder(cv = 5)\n",
    "\n",
    "te_cols = [\"Company\", \"CPU_series\", \"GPU_series\"]\n",
    "\n",
    "# Setting up the tranformer\n",
    "ct = ColumnTransformer(transformers = [\n",
    "    (\"target_enc\", encoder, te_cols)\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "# To turn the output into a dataframe not array\n",
    "ct.set_output(transform = \"pandas\")\n",
    "\n",
    "X = path_df.drop([\"Price_euros\",\"Price_transformed\"],axis = 1)\n",
    "y = path_df[\"Price_transformed\"]\n",
    "encoded_data = ct.fit_transform(X, y)\n",
    "\n",
    "path_df[\"Company_encoded\"] = encoded_data[\"target_enc__Company\"].round(2)\n",
    "path_df[\"CPU_series_encoded\"] = encoded_data[\"target_enc__CPU_series\"].round(2)\n",
    "path_df[\"GPU_series_encoded\"] = encoded_data[\"target_enc__GPU_series\"].round(2)\n",
    "path_df[[\"Company_encoded\",\"GPU_series_encoded\",\"CPU_series_encoded\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0214d02",
   "metadata": {},
   "source": [
    "### `TypeName`, `OS`, `Screen`, `CPU_company`, `PrimaryStorageType`, `SecondaryStorageType`, `GPU_company` **OHE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad9aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [\"TypeName\", \"OS\", \"Screen\", \"CPU_company\", \"PrimaryStorageType\", \"SecondaryStorageType\", \"GPU_company\"]\n",
    "\n",
    "# Safety check incase of new data\n",
    "ohe = OneHotEncoder(handle_unknown = \"ignore\", sparse_output = False, drop = \"first\")\n",
    "\n",
    "ct = ColumnTransformer(transformers = [\n",
    "    (\"ohe\", ohe, ohe_cols)\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "ct.set_output(transform = \"pandas\")\n",
    "\n",
    "encoded_data = ct.fit_transform(path_df)\n",
    "\n",
    "rename_mappings = {\n",
    "    col: col.replace(\"ohe__\", \"\").replace(\" \", \"_\") \n",
    "    for col in encoded_data.columns if col.startswith(\"ohe__\")\n",
    "}\n",
    "\n",
    "renamed_cols = encoded_data[rename_mappings.keys()].rename(columns = rename_mappings)\n",
    "path_df = pd.concat([path_df, renamed_cols], axis = 1)\n",
    "path_df[renamed_cols.columns] = path_df[renamed_cols.columns].astype(int)\n",
    "\n",
    "path_df[renamed_cols.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb83a70",
   "metadata": {},
   "source": [
    "### `Touchscreen`, `IPSpanel`, `RetinaDisplay` **BE (Binary Encoding)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdb202",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = [\"Touchscreen\", \"IPSpanel\", \"RetinaDisplay\"]\n",
    "\n",
    "ord_enc = OrdinalEncoder(dtype= int)\n",
    "\n",
    "encoded_names = [f\"{col}_encoded\" for col in binary_cols]\n",
    "\n",
    "path_df[encoded_names] = ord_enc.fit_transform(path_df[binary_cols])\n",
    "\n",
    "path_df[encoded_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751311dc",
   "metadata": {},
   "source": [
    "### `ScreenW`, `ScreenH` **Interaction generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eed630",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df[\"Pixels\"] = (path_df[\"ScreenW\"] * path_df[\"ScreenH\"]).astype(int)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.histplot(x = \"Pixels\",\n",
    "            data = path_df,\n",
    "            color = \"grey\",\n",
    "            edgecolor = \"black\",\n",
    "            bins = 20)\n",
    "plt.title(\"Pixels distribution\")\n",
    "\n",
    "\n",
    "path_df[\"Pixels\"] = path_df[\"Pixels\"].apply(np.log1p)\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "sns.histplot(x = \"Pixels\",\n",
    "            data = path_df,\n",
    "            color = \"grey\",\n",
    "            edgecolor = \"black\",\n",
    "            bins = 20)\n",
    "plt.title(\"Pixels distribution (Logged)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d623286",
   "metadata": {},
   "source": [
    "### `Inches`, `Ram`, `Weight`, `PrimaryStorage`, `SecondaryStorage`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c71119",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_col_hist = [\"Inches\", \"Ram\", \"Weight\", \"PrimaryStorage\", \"SecondaryStorage\", \"Pixels\"]\n",
    "\n",
    "for cols in numerical_col_hist:\n",
    "    plt.figure(figsize = (12,8))\n",
    "    sns.histplot(x = cols,\n",
    "                 data = path_df,\n",
    "                 color = \"grey\",\n",
    "                 edgecolor = \"black\",\n",
    "                 bins = 20)\n",
    "    plt.title(f\"{cols} distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "path_df[\"PrimaryStorage\"] = path_df[\"PrimaryStorage\"].apply(np.log1p)\n",
    "path_df[\"SecondaryStorage\"] = path_df[\"SecondaryStorage\"].apply(np.log1p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51575cfa",
   "metadata": {},
   "source": [
    "### Final Touches before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_features = ['Ram', 'PrimaryStorage', 'SecondaryStorage']\n",
    "standard_features = ['Inches', 'CPU_freq', 'Pixels', \"Weight\"]\n",
    "exclude_features = [\"Price_euros\", \"Price_transformed\", \"ScreenW\", \"ScreenH\"]\n",
    "\n",
    "numerical_cols = path_df.select_dtypes(include = \"number\").drop(columns = exclude_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de2fb0",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995aac79",
   "metadata": {},
   "source": [
    "## Predictive Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295703e7",
   "metadata": {},
   "source": [
    "### Setting up data for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6fc588",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numerical_cols\n",
    "y = path_df[\"Price_transformed\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 25)\n",
    "\n",
    "print(f\"Training on {X_train.shape[0]} laptops.\")\n",
    "print(f\"Testing on {X_test.shape[0]} laptops.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6efc41",
   "metadata": {},
   "source": [
    "### VIF\n",
    "To check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f07d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ColumnTransformer(transformers = [\n",
    "    (\"rob\", RobustScaler(), robust_features),\n",
    "    (\"std\", StandardScaler(), standard_features)\n",
    "], remainder = \"passthrough\")\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_vif = pd.DataFrame()\n",
    "X_vif[\"Features\"] = X.columns\n",
    "X_vif[\"VIF\"] = [variance_inflation_factor(X_train_scaled, i) for i in range(X_train_scaled.shape[1])]\n",
    "\n",
    "display(X_vif.sort_values(by=\"VIF\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f5899e",
   "metadata": {},
   "source": [
    "### ElasticNet\n",
    "Chose elasticnet instead of a regular linear regression due to lasso and ridge regression regularization **(coefficient punishment)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c624910",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_model = ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], cv = 5, random_state = 5)\n",
    "\n",
    "en_model.fit(X_train_scaled, y_train),\n",
    "y_pred_log_en = en_model.predict(X_test_scaled)\n",
    "\n",
    "y_pred_euros = np.expm1(y_pred_log_en)\n",
    "y_actual_euros = np.expm1(y_pred_log_en)\n",
    "\n",
    "print(f\"Best L1 Ratio: {en_model.l1_ratio_}\")\n",
    "print(f\"Best Alpha: {en_model.alpha_:.4f}\")\n",
    "print(f\"R2 Score: {r2_score(y_test, y_pred_log_en):.2f}\")\n",
    "print(f\"MAE: {mean_squared_error(y_test, y_pred_log_en):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156264d",
   "metadata": {},
   "source": [
    "### Linearity Assumptions\n",
    "The data passes most assumptions (with slight deviation in QQPlot) but overall it's solid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc085330",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = lin_model.predict(X_test_scaled)\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "# =================================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# 1. Linearity\n",
    "axes[0, 0].scatter(y_pred, residuals, alpha=0.5, color=\"grey\", edgecolor=\"black\")\n",
    "axes[0, 0].axhline(y=0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "axes[0, 0].set_xlabel(\"Predicted Values\")\n",
    "axes[0, 0].set_ylabel(\"Residuals\")\n",
    "axes[0, 0].set_title(\"1. Linearity: Residuals vs Predicted\")\n",
    "\n",
    "# 2. Normality of Residuals\n",
    "sm.qqplot(residuals, line=\"45\", ax=axes[0, 1], markerfacecolor=\"grey\", markeredgecolor=\"black\")\n",
    "axes[0, 1].set_title(\"2. Normality: Q-Q Plot of Residuals\")\n",
    "\n",
    "# 3. Homoscedasticity\n",
    "standardized_residuals = (residuals - residuals.mean()) / residuals.std()\n",
    "axes[1, 0].scatter(y_pred, np.sqrt(np.abs(standardized_residuals)), alpha=0.5, color=\"grey\", edgecolor=\"black\")\n",
    "axes[1, 0].set_xlabel(\"Predicted Values\")\n",
    "axes[1, 0].set_ylabel(\"√|Standardized Residuals|\")\n",
    "axes[1, 0].set_title(\"3. Homoscedasticity: Scale-Location Plot\")\n",
    "\n",
    "# 4. Residuals Distribution\n",
    "sns.histplot(residuals, kde=True, color=\"grey\", edgecolor=\"black\", ax=axes[1, 1])\n",
    "axes[1, 1].axvline(x=0, color=\"red\", linestyle=\"--\", linewidth=2)\n",
    "axes[1, 1].set_title(\"4. Residuals Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================================================================\n",
    "\n",
    "# Shapiro-Wilk Test for Normality\n",
    "sample_residuals = residuals.sample(min(500, len(residuals)), random_state=42) if len(residuals) > 500 else residuals\n",
    "shapiro_stat, shapiro_p = stats.shapiro(sample_residuals)\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ASSUMPTION TEST RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"\\n1. Normality (Shapiro-Wilk Test):\")\n",
    "print(f\"   Statistic: {shapiro_stat:.4f}, p-value: {shapiro_p:.4f}\")\n",
    "print(f\"   Result: {'✓ Normal' if shapiro_p > 0.05 else '✗ Not Normal'} (α=0.05)\")\n",
    "\n",
    "# Durbin-Watson Test for autocorrelation\n",
    "dw_stat = durbin_watson(residuals)\n",
    "print(f\"\\n2. Independence (Durbin-Watson Test):\")\n",
    "print(f\"   Statistic: {dw_stat:.4f}\")\n",
    "print(f\"   Result: {'✓ No autocorrelation' if 1.5 < dw_stat < 2.5 else '✗ Possible autocorrelation'} (ideal: ~2)\")\n",
    "\n",
    "# Breusch-Pagan Test for Homoscedasticity\n",
    "X_test_with_const = sm.add_constant(X_test_scaled)\n",
    "bp_stat, bp_p, _, _ = het_breuschpagan(residuals, X_test_with_const)\n",
    "print(f\"\\n3. Homoscedasticity (Breusch-Pagan Test):\")\n",
    "print(f\"   Statistic: {bp_stat:.4f}, p-value: {bp_p:.4f}\")\n",
    "print(f\"   Result: {'✓ Homoscedastic' if bp_p > 0.05 else '✗ Heteroscedastic'} (α=0.05)\")\n",
    "\n",
    "# Model Performance\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Model Performance\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"R² Score: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "print(f\"Mean Residual: {residuals.mean():.6f} (should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e24a10",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
